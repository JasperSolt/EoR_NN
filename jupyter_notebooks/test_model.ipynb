{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "898996a5-1698-4c5e-8425-738947c4df76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Plot model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b9eed80-76d4-4e39-b555-d16edb83a4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.5 1.  1.5 2.  2.5 3. ]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('ps')\n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "rc('text',usetex=True)\n",
    "rc('text.latex', preamble=r'\\usepackage{color}')\n",
    "\n",
    "def plot_model_predictions(npz_names, fname=None, labels=None, titles=None):\n",
    "    dlabels = labels\n",
    "    if not dlabels:\n",
    "        dlabels = npz_names\n",
    "    \n",
    "    n_models = len(npz_names)\n",
    "    model_colors = ['c','m','y']\n",
    "\n",
    "\n",
    "\n",
    "    #Layout\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, sharey=True, figsize=(10,4), layout='tight')\n",
    "    ax1, ax2, ax3 = axs\n",
    "    \n",
    "    ax1.set_ylabel(f'Predicted Duration')\n",
    "    ticks = np.arange(0.0, 3.5, 0.5)\n",
    "    print(ticks)\n",
    "    ax1.set_yticks(ticks)\n",
    "\n",
    "    #ax2.get_yaxis().set_visible(False)\n",
    "    \n",
    "    #ax3.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "    #ax1 formatting\n",
    "    for j, ax in enumerate(axs):\n",
    "        ax.set_xlabel(r'True Duration')\n",
    "        ax.set_xticks(ticks)\n",
    "\n",
    "        ax.grid(True)\n",
    "        if titles: ax.set_title(titles[j])\n",
    "\n",
    "        recs = []\n",
    "        for i in range(n_models):\n",
    "            recs.append(mpatches.Rectangle((0,0),0.5,0.5, fc=model_colors[i]))\n",
    "        ax.legend(recs, dlabels)\n",
    "        \n",
    "        #load and plot the parameter prediction data for each model\n",
    "        targets, pred, err = np.array([]), np.array([]), np.array([])\n",
    "        for i, name in enumerate(npz_names[j]):\n",
    "            result = np.load(name)\n",
    "    \n",
    "            model_targets = np.array(result['targets'][:, 0])\n",
    "            model_pred = np.array(result['predictions'][:, 0])\n",
    "            model_err = 100.0*(1-model_pred/model_targets)\n",
    "    \n",
    "            ax.scatter(model_targets, model_pred, alpha=0.7, s=1.5, c=model_colors[i])\n",
    "    \n",
    "            targets = np.append(targets,model_targets)\n",
    "            pred = np.append(pred, model_pred)\n",
    "            err = np.append(err, model_err)\n",
    "        \n",
    "        #find axis limits \n",
    "        mintargets, maxtargets = np.min(targets), np.max(targets)\n",
    "\n",
    "        ax.set_xlim(0.0, 3.0)\n",
    "        ax.set_ylim(0.0, 3.0)\n",
    "        \n",
    "        #Plot target line\n",
    "        ideal = np.linspace(0.0,3.0,10)\n",
    "        ax.plot(ideal, ideal, 'k--', alpha=0.3, linewidth=1.5)\n",
    "    \n",
    "        ax.set_aspect('equal')\n",
    "    #Save\n",
    "    if fname:\n",
    "        plt.savefig(fname, dpi=128)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "pairs = [(\"p21c\",\"ctrpx\",\"zreion\"), (\"p21c\",\"zreion\",\"ctrpx\"), (\"zreion\",\"ctrpx\",\"p21c\")]\n",
    "titles = [\n",
    "    r\"Trained on \\textcolor{green}{21cmFAST} and \\textcolor{blue}{Central Pixel}\", \n",
    "    r\"Trained on \\textcolor{green}{21cmFAST} and \\textcolor{red}{RLS}\", \n",
    "    r\"Trained on \\textcolor{blue}{Central Pixel} and \\textcolor{red}{RLS}\"]\n",
    "\n",
    "path = \"/users/jsolt/FourierNN/trained_models\"\n",
    "labels = [\"Adversarial\", \"Non-Adversarial\"]\n",
    "\n",
    "npz_names = []\n",
    "\n",
    "for m1, m2, m3 in pairs:\n",
    "    model_names = [\n",
    "        f\"adversarial_v02_{m1}_{m2}_alpha0.01_lr0.001_ws0.0_s02\",\n",
    "        #f\"adversarial_null_v01_{m1}_{m2}_ws0.0_s03\"\n",
    "        f\"mixed_{m1}_{m2}_m256_dur_ws0.0_lr0.003_bs64_v02\"\n",
    "    ]\n",
    "\n",
    "    npz_names.append([f\"{path}/{name}/pred_{name}_on_{m3}_test.npz\" for name in model_names])\n",
    "\n",
    "\n",
    "plot_model_predictions(npz_names, fname=\"adv_vs.jpeg\", titles=titles, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df27efc-6c2b-4044-8d6c-9cf01c772be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = [\"21cmFAST\",\"Central Pixel\",\"RLS\"]\n",
    "\n",
    "npz_names = []\n",
    "\n",
    "for m1, m2, _ in pairs:\n",
    "    name = f\"adversarial_v02_{m1}_{m2}_alpha0.01_lr0.003_ws0.0_s03\"\n",
    "\n",
    "    npz_names.append([f\"{path}/{name}/pred_{name}_on_{m3}_test.npz\" for m3 in [\"p21c\",\"ctrpx\",\"zreion\"]])\n",
    "\n",
    "\n",
    "plot_model_predictions(npz_names, titles=titles, labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f272daa-5c8b-4a01-8b87-339bb594d8bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testing Adversarial Model\n",
    "Load packages and initialize parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b4935-4784-48b9-9ad4-e62f734e679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from EoR_Dataset import EORImageDataset\n",
    "from adversarial_model import encoder, discriminator, regressor\n",
    "from hyperparams import Model_Hyperparameters, Dataset_Hyperparameters\n",
    "\n",
    "def get_path(model_sim, ws):\n",
    "    if model_sim == \"p21c\":\n",
    "        dp = f\"/users/jsolt/data/jsolt/21cmFAST_sims/p21c14/p21c14_ws{ws}_trnspsd_meanremoved_norm.hdf5\"\n",
    "    elif model_sim == \"zreion\":\n",
    "        dp = f\"/users/jsolt/data/jsolt/zreion_sims/zreion21/zreion21_transposed_ws{ws}.hdf5\"\n",
    "    elif model_sim == \"ctrpx\":\n",
    "        dp = f\"/users/jsolt/data/jsolt/21cmFAST_centralpix_v04/21cmFAST_centralpix_v04_transposed_ws{ws}.hdf5\"\n",
    "    return dp\n",
    "\n",
    "batchsize = 4\n",
    "scale = 256\n",
    "zindices = [x*17 for x in range(0, 30)]\n",
    "ws=0.0\n",
    "\n",
    "param = 'dur'\n",
    "param_index = 0 if param==\"mdpt\" else 1\n",
    "\n",
    "train_sims = [\"p21c\"] \n",
    "\n",
    "data_paths = []\n",
    "for ts in train_sims:\n",
    "    data_paths.append(get_path(ts, ws))\n",
    "\n",
    "hp_data = Dataset_Hyperparameters(\n",
    "    train_sims, \n",
    "    data_paths, \n",
    "    zindices, \n",
    "    batchsize, \n",
    "    subsample_scale=scale, \n",
    "    param=param_index,\n",
    "    n_limit=batchsize*2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43addfa2-0c91-416d-8293-adb57cfaf96c",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9c31b-2b58-4133-85f4-6ff66dece97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "print(\"Loading training data...\")\n",
    "\n",
    "test_data = EORImageDataset(\"test\", hp_data)\n",
    "test_dataloader = DataLoader(train_data, batch_size=batchsize, shuffle=True)\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    print(len(train_dataloader))\n",
    "    print(y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954014c8-ba11-4376-9012-01200bcd09bb",
   "metadata": {},
   "source": [
    "Test in context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf03f6-c70d-4d06-a9e0-01813f275304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_Fourier_NN import train_adversarial_NN\n",
    "from predict_Fourier_NN import predict_adversarial_NN\n",
    "from plot_model_results import plot_model_predictions\n",
    "\n",
    "\n",
    "model_name = \"test_adversarial\"\n",
    "model_dir = \"models/\" + model_name\n",
    "epochs = 2\n",
    "lr=0.01\n",
    "alpha=1.0\n",
    "\n",
    "hp_model = Model_Hyperparameters(model_name, hp_train_data, epochs=epochs, init_lr=lr, alpha=alpha)\n",
    "\n",
    "#print(\"Training Loop\")\n",
    "train_adversarial_NN(hp_model)\n",
    "\n",
    "print(\"Prediction Loop\")\n",
    "#plot_save_dir = f\"{hp_model.MODEL_DIR}/pred_plots\"\n",
    "psdirs = [f\"models/plots/{hp_model.MODEL_NAME}\", f\"{hp_model.MODEL_DIR}/pred_plots\"]\n",
    "\n",
    "\n",
    "for plot_save_dir in psdirs:\n",
    "    if not os.path.isdir(plot_save_dir): os.mkdir(plot_save_dir)\n",
    "    \n",
    "all_sims = ['zreion', 'p21c', 'ctrpx']\n",
    "for pred_sims in [train_sims, all_sims]:\n",
    "    pred_set = [Dataset_Hyperparameters([x], [get_path(x, ws)], zindices, batchsize, subsample_scale=scale, param=param_index, n_limit=8) for x in pred_sims]\n",
    "    pred_files_test = [predict_adversarial_NN(hp_model=hp_model, hp_test=p, mode=\"test\") for p in pred_set]\n",
    "\n",
    "    print('Plotting...')\n",
    "    for plot_save_dir in psdirs:\n",
    "        \n",
    "        fig_name_test = f\"{plot_save_dir}/duration_{hp_model.MODEL_NAME}\"\n",
    "    \n",
    "        for sim in pred_sims:\n",
    "            fig_name_test += f\"_{sim}\"\n",
    "        \n",
    "        title = model_name\n",
    "        labels = pred_sims\n",
    "        \n",
    "        plot_model_predictions(pred_files_test, fig_name_test, param_index, labels, title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f0428-4467-4b25-b6b8-e648317cbbe8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Loss Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb93d0d-2ba8-4303-9b61-31d739598eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plot_model_results import plot_loss\n",
    "\n",
    "path = \"models/adversarial_p21c_zreion_ws0.0_alpha0.1_v01/adversarial_p21c_zreion_ws0.0_alpha0.1_v01\"\n",
    "encloss = f\"{path}_enc_loss.npz\"\n",
    "regloss = f\"{path}_reg_loss.npz\"\n",
    "disloss = f\"{path}_dis_loss.npz\"\n",
    "\n",
    "with np.load(encloss) as loss:\n",
    "    plot_loss(loss, f\"{path}_enc_loss.png\", title=\"adversarial_p21c_zreion_ws0.0_alpha0.1_v01 Encoder Loss (linear)\", logloss=False)\n",
    "\n",
    "with np.load(regloss) as loss:\n",
    "    plot_loss(loss, f\"{path}_reg_loss.png\", title=\"adversarial_p21c_zreion_ws0.0_alpha0.1_v01 Regressor Loss (linear)\", logloss=False)\n",
    "\n",
    "with np.load(disloss) as loss:\n",
    "    plot_loss(loss, f\"{path}_dis_loss.png\", title=\"adversarial_p21c_zreion_ws0.0_alpha0.1_v01 Discriminator Loss (linear)\", logloss=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44bc8d-2fc9-491d-bdfe-61d8f0b5bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plot_model_results import plot_loss\n",
    "\n",
    "path = \"models/adversarial_zreion_ctrpx_ws0.0_alpha0.1_beta0.1_v01/adversarial_zreion_ctrpx_ws0.0_alpha0.1_beta0.1_v01\"\n",
    "encloss = f\"{path}_enc_loss.npz\"\n",
    "regloss = f\"{path}_reg_loss.npz\"\n",
    "disloss = f\"{path}_dis_loss.npz\"\n",
    "\n",
    "loss={}\n",
    "with np.load(encloss) as data:\n",
    "    loss[\"train\"]=np.clip(data[\"train\"], 0.09, 0.11)\n",
    "    loss[\"val\"]=np.clip(data[\"val\"],  0.09, 0.11)\n",
    "    plot_loss(loss, f\"{path}_enc_loss.png\", title=\"adversarial_p21c_zreion_ws0.0_alpha0.1_v01 Encoder Loss (linear)\", logloss=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16cc41-148e-44e2-9c27-e7584254a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "modules = [\"enc\", \"reg\", \"dis\"]\n",
    "sims = [\"zreion\", \"ctrpx\"]\n",
    "allsims = [\"p21c\", \"zreion\", \"ctrpx\"]\n",
    "start = 10\n",
    "for alpha in [0.1]:\n",
    "    for ws in [0.0]:\n",
    "        name = f\"adversarial_v02_{sims[0]}_{sims[1]}_alpha{alpha}_lr0.003_ws{ws}\"\n",
    "        lossdict = {}\n",
    "        for module in modules:\n",
    "            lossdict[module] = {}\n",
    "            path = f\"models/{name}/{name}_{module}_loss.npz\"\n",
    "            with np.load(path) as data:\n",
    "                lossdict[module]['train']=pd.DataFrame(data['train'][start:])\n",
    "                lossdict[module]['val']=pd.DataFrame(data['val'][start:])\n",
    "        \n",
    "        fname = f\"models/{name}/{name}_all_loss.png\"\n",
    "        title = f\"{name} Loss\"\n",
    "\n",
    "\n",
    "\n",
    "        n_axes =len(lossdict)\n",
    "    \n",
    "        fig, axs = plt.subplots(n_axes, 1, sharex=True, tight_layout=True, figsize=(6, 12))\n",
    "        \n",
    "        fig.suptitle(title)\n",
    "        for r, (label, loss) in enumerate(lossdict.items()):\n",
    "            axs[r].grid(True)\n",
    "            \n",
    "        \n",
    "            axs[r].set_ylabel('MSE Loss (tanh + exp running avg')\n",
    "            \n",
    "            epochs = len(loss[\"train\"])\n",
    "            axs[r].plot(np.arange(start+1, epochs+start+1), np.tanh(loss[\"val\"]).ewm(com=5.0).mean(), label='Validation loss', linewidth=0.7)\n",
    "            axs[r].plot(np.arange(start+1, epochs+start+1), np.tanh(loss[\"train\"]).ewm(com=5.0).mean(), label='Training loss', linewidth=0.7)\n",
    "            axs[r].set_title(label)\n",
    "            axs[r].legend()\n",
    "            axs[r].axvline(1000, color='red', ls=\":\", label=\"label\")\n",
    "        axs[-1].set_xlabel('Epochs')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf3fdc-1db3-4e68-bc78-d21c32794a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_loss_grid(lossdict, fname, title=\"\", start=10, steps=[], steplabels=[]):\n",
    "    fig, axs = plt.subplots(len(lossdict), 1, sharex=True, tight_layout=True, figsize=(6, 12))\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    for r, (label, loss) in enumerate(lossdict.items()):\n",
    "        axs[r].grid(True)\n",
    "        axs[r].set_ylabel('MSE Loss (tanh + exp running avg')\n",
    "    \n",
    "        train_loss = pd.DataFrame(np.tanh(loss['train'][start:])).ewm(com=5.0).mean()\n",
    "        val_loss = pd.DataFrame(np.tanh(loss['val'][start:])).ewm(com=5.0).mean()\n",
    "        \n",
    "        epochs = np.arange(start+1, len(train_loss)+start+1)\n",
    "\n",
    "        axs[r].plot(epochs, val_loss, label='Validation', linewidth=0.7)\n",
    "        axs[r].plot(epochs, train_loss, label='Training', linewidth=1.0)\n",
    "        \n",
    "        for i in range(len(steps)):\n",
    "            axs[r].axvline(steps[i], color='red', ls=\":\", alpha=0.5)\n",
    "            axs[r].text(\n",
    "                steps[i]-0.02*(axs[r].get_xlim()[1]), \n",
    "                axs[r].get_ylim()[1] - 0.03*(axs[r].get_ylim()[1]-axs[r].get_ylim()[0]), \n",
    "                steplabels[i],\n",
    "                horizontalalignment='right',\n",
    "                verticalalignment='top',\n",
    "                color='#000000',\n",
    "                backgroundcolor='#eeeeeec0',)\n",
    "        \n",
    "        axs[r].set_title(label)\n",
    "        axs[r].legend(loc='upper left')\n",
    "    axs[-1].set_xlabel('Epochs')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "modules = [\"enc\", \"reg\", \"dis\"]\n",
    "sims = [\"zreion\", \"ctrpx\"]\n",
    "allsims = [\"p21c\", \"zreion\", \"ctrpx\"]\n",
    "steplabels = [\"lr=0.003\", \"lr=0.001\", \"lr=0.003\"]\n",
    "\n",
    "\n",
    "for alpha in [0.01]:\n",
    "    for ws in [0.0]:\n",
    "        names = [\n",
    "            f\"adversarial_v02_{sims[0]}_{sims[1]}_alpha{alpha}_lr0.003_ws{ws}\",\n",
    "            f\"adversarial_v02_{sims[0]}_{sims[1]}_alpha{alpha}_lr0.001_ws{ws}_s02\",\n",
    "            f\"adversarial_v02_{sims[0]}_{sims[1]}_alpha{alpha}_lr0.003_ws{ws}_s03\",\n",
    "        ]\n",
    "        lossdict = {}\n",
    "        for module in modules:\n",
    "            lossdict[module] = {}\n",
    "            npz_names = [f\"models/{name}/{name}_{module}_loss.npz\" for name in names]\n",
    "            lossdict[module][\"train\"]=np.array([])\n",
    "            lossdict[module][\"val\"]=np.array([])\n",
    "            steps = []\n",
    "            for npz_name in npz_names:\n",
    "                with np.load(npz_name) as data:\n",
    "                    lossdict[module][\"train\"] = np.concatenate([lossdict[module][\"train\"], data[\"train\"]])\n",
    "                    lossdict[module][\"val\"] = np.concatenate([lossdict[module][\"val\"], data[\"val\"]])\n",
    "                    steps.append(len(lossdict[module][\"train\"]))\n",
    "\n",
    "        title = f\"{name} Loss\"\n",
    "        print(steps)\n",
    "        plot_loss_grid(lossdict, \"\", title, steps=steps, steplabels=steplabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646bca70-e49f-4883-afd2-94fe423a46ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19d0953-4033-428f-b38b-92aece49d5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim 0: 10 samples\n",
      "Total number of samples: 10\n",
      "Loading cube 0 of 10 from sim 0 (pointer = 0)...\n",
      "torch.Size([30, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from EoR_Dataset import EORImageDataset\n",
    "from autoencoder import autoencoder\n",
    "from hyperparams import Dataset_Hyperparameters\n",
    "import numpy as np\n",
    "\n",
    "###\n",
    "# Load Data\n",
    "###\n",
    "ws=0.0\n",
    "sims = [\"ctrpx\",] \n",
    "data_paths = [f\"/users/jsolt/data/jsolt/21cmFAST_centralpix_v05/21cmFAST_centralpix_v05_transposed_ws{ws}.hdf5\"]\n",
    "\n",
    "hp = Dataset_Hyperparameters(\n",
    "                                    sims, \n",
    "                                    data_paths, \n",
    "                                    zindices=np.linspace(0, 511, 30, dtype=int), \n",
    "                                    batchsize=1, \n",
    "                                    subsample_scale=256, \n",
    "                                    param=1,\n",
    "                                    n_limit=10,\n",
    ")\n",
    "\n",
    "data = EORImageDataset(\"test\", hp)\n",
    "\n",
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4359cccb-62c7-4042-912b-4f07a0f64d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{24.0: 'models/autoencoder_v24.0_ctrpx_ws0.0/autoencoder_v24.0_ctrpx_ws0.0.pth', 25.0: 'models/autoencoder_v25.0_ctrpx_ws0.0/autoencoder_v25.0_ctrpx_ws0.0.pth', 26.0: 'models/autoencoder_v26.0_ctrpx_ws0.0/autoencoder_v26.0_ctrpx_ws0.0.pth', 27.0: 'models/autoencoder_v27.0_ctrpx_ws0.0/autoencoder_v27.0_ctrpx_ws0.0.pth'}\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Load Model(s)\n",
    "###\n",
    "versions = [24.0, 25.0, 26.0, 27.0]\n",
    "names = {v: f\"autoencoder_v{v:0>4}_ctrpx_ws{ws}\" for v in versions}\n",
    "paths = {v: f\"models/{name}/{name}.pth\" for v, name in names.items()}\n",
    "models = {}\n",
    "\n",
    "for v, path in paths.items():\n",
    "    models[v] = autoencoder()\n",
    "    if torch.cuda.is_available(): models[v].cuda()\n",
    "    models[v].load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddf18dc-ed2f-40ca-b7a7-4bcfc96c44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from plot_model_results import plot_image_rows\n",
    "\n",
    "zind = np.linspace(0, 29, 30, dtype=int)\n",
    "\n",
    "for lci in [0,1,2,8]:\n",
    "    rows = []\n",
    "    with torch.no_grad():\n",
    "        X, _, _, _ = data[lci]\n",
    "        inpt = X[None, :, :, :]\n",
    "        rows.append(inpt[0,zind])\n",
    "\n",
    "        for v in versions:\n",
    "            model=models[v]\n",
    "            model.eval()\n",
    "\n",
    "            outpt = model(inpt)\n",
    "            rows.append(outpt[0,zind])\n",
    "\n",
    "    \n",
    "    title = f\"lightcone {lci}\"\n",
    "    fname = f\"model_compare_lightcone_{lci}.png\"\n",
    "    rowlabels = [\"input\",\"control\",\"shufflez\",\"zoomin\",\"shufflez + zoomin\"]\n",
    "    plot_image_rows(rows, title=title, fname=fname, collabels=zind, rowlabels=rowlabels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ebad60f-89cf-4108-8757-e64fcd897783",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_model_results import plot_image_grid, plot_image_rows\n",
    "\n",
    "\n",
    "lci=2\n",
    "for lci in range(9):\n",
    "    X, *_ = data[lci]\n",
    "    inpt = X[None, :, :, :].detach()\n",
    "    outpt = model(inpt).detach()\n",
    "    \n",
    "    metric = np.zeros_like(inpt.numpy())\n",
    "    for i in range(30):\n",
    "        metric[0,i] = np.corrcoef(inpt[0,i], outpt[0,i])[256:,:256]\n",
    "        #metric[0,i] = np.where(np.isnan(metric[0,i]), 0.0, metric[0,i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    zsample = np.linspace(0, 29, 6, dtype=int)\n",
    "    rows = [inpt[0,zsample], outpt[0,zsample], metric[0,zsample]]\n",
    "    rowlabels = ['input', 'output', 'corrcoef']\n",
    "    plot_image_rows(rows, rowlabels=rowlabels, collabels=zsample, title=f'ctrpx lightcone {lci}', fname=f'ctrpx_lightcone{lci}_corrcoef.png', vmin=-1, vmax=1)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0abae79-4173-4cb5-bcc7-95c6a2001d1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f18827c1-6028-41ee-9802-1cedd6acb8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim 0: 8 samples\n",
      "Total number of samples: 8\n",
      "Loading cube 0 of 8 from sim 0 (pointer = 0)...\n",
      "torch.Size([30, 256, 256])\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from EoR_Dataset import EORImageDataset\n",
    "from variational_autoencoder import vae\n",
    "from hyperparams import DataHyperparameters, ModelHyperparameters\n",
    "import numpy as np\n",
    "\n",
    "###\n",
    "# Load Data\n",
    "###\n",
    "ws=0.0\n",
    "sims = [\"ctrpx\",] \n",
    "data_paths = [f\"/users/jsolt/data/jsolt/21cmFAST_centralpix_v05/21cmFAST_centralpix_v05_transposed_ws{ws}.hdf5\"]\n",
    "\n",
    "hp_train_data = DataHyperparameters(\n",
    "    sims=sims,\n",
    "    data_paths=data_paths,\n",
    "    zindices=np.linspace(0, 511, 30, dtype=int).tolist(),\n",
    "    boxlength=256,\n",
    "    param_index=1,\n",
    "    ztransform=[\"zoomin\"],\n",
    "    lenlimit=8,\n",
    ")\n",
    "\n",
    "\n",
    "data = EORImageDataset(\"test\", hp_train_data)\n",
    "\n",
    "print(data[0][0].shape)\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049adfb0-a627-411c-9859-91f513714ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([3.0, 4.0])\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Load Model(s)\n",
    "###\n",
    "hd1 = 16\n",
    "hd2 = 32\n",
    "ld = 64\n",
    "models = {}\n",
    "names = {}\n",
    "\n",
    "ks_dict = {3.0:5, 4.0:7}\n",
    "pad_dict = {3.0:2, 4.0:3}\n",
    "\n",
    "for i in [3.0, 4.0]:\n",
    "    name = f\"single_channel_vae_v{i:0>4}_ctrpx_ws0.0\"\n",
    "    names[i] = name\n",
    "\n",
    "    hp_model = ModelHyperparameters(\n",
    "        model_name=name,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        training_data_hp=hp_train_data, \n",
    "        batchsize=64,\n",
    "        epochs=1000, \n",
    "        initial_lr=1e-3,\n",
    "        lr_milestones=[],\n",
    "        lr_gamma=0.1,\n",
    "        parent_model=None,\n",
    "        input_dim=1, \n",
    "        hidden_dim_1=hd1,\n",
    "        hidden_dim_2=hd2,\n",
    "        latent_dim=ld,\n",
    "        kernel_size=ks_dict[i],\n",
    "        stride=2,\n",
    "        padding=pad_dict[i]\n",
    "    )\n",
    "    path = f\"{hp_model.model_dir}/{hp_model.model_name}.pth\" #f\"trained_models/{name}/{name}.pth\" \n",
    "    \n",
    "    models[i] = vae(hp_model)\n",
    "    models[i].load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "\n",
    "print(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5811e62b-6916-4198-9113-8eb1e2252775",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import numpy as np\n",
    "import plot_model_results\n",
    "importlib.reload(plot_model_results)\n",
    "\n",
    "zind = np.linspace(0, 29, 8, dtype=int)\n",
    "\n",
    "for lci in [2]:\n",
    "    rows = {}\n",
    "    with torch.no_grad():\n",
    "        X, *_, = data[lci]\n",
    "        inpt = X[None, zind, :, :]\n",
    "        rows['input'] = inpt[0]\n",
    "\n",
    "        for i in [3.0, 4.0]:\n",
    "            model = models[i]\n",
    "            model.eval()\n",
    "\n",
    "            outpt = torch.zeros_like(inpt)\n",
    "            for j in range(len(zind)):\n",
    "                slice = inpt[0,j]\n",
    "                outpt[0,j] = model.decode(model.encode(slice[None,None,:,:])[0])\n",
    "            rows[f\"(v{i:0>4})\"] = outpt[0]\n",
    "\n",
    "            \n",
    "    title = f\"Single-Channel VAE: Lightcone {lci}\"\n",
    "    fname = f\"single_channel_vae_ctrpx_ws0.0_lci{lci}_result.png\"\n",
    "    plot_model_results.plot_image_rows(rows, collabels=zind, title=title, fname=fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1466dbab-324d-4698-aad0-188924c747f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss plot saved.\n",
      "Loss plot saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plot_model_results\n",
    "importlib.reload(plot_model_results)\n",
    "\n",
    "names = [\n",
    "    \"single_channel_vae_v01.0_ctrpx_ws0.0_16_32_64_lr0.0001\",\n",
    "    \"single_channel_vae_v03.0_ctrpx_ws0.0\",\n",
    "    \"single_channel_vae_v04.0_ctrpx_ws0.0\",\n",
    "]\n",
    "\n",
    "keys = ['train','val']\n",
    "for key in keys:\n",
    "    loss = {}\n",
    "    for name in names:\n",
    "        loss_path = f\"trained_models/{name}/{name}_loss.npz\"\n",
    "        with np.load(loss_path) as f:\n",
    "            loss[name] = f[key][:500]\n",
    "    fname = f\"single_channel_vae_kernel_size_loss_comparison.png\"\n",
    "    title = f\"Single-Channel VAE: Kernel Size Loss Comparison\"\n",
    "    plot_model_results.plot_loss_comparison(loss, fname, title=title, transform=np.log10, ylabel=\"Loss (log)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9bdfda-2b2d-4726-b826-3bb030d3c3e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hyperparameter encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f626babc-96c9-496d-93a5-cb1c71b0fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelHyperparameters(epochs=2000, hp_data=DataHyperparameters(batchsize=64, boxlength=256, data_paths=['path1', 'path2'], lenlimit=200, n_channels=30, n_datasets=2, param_index=1, sims=['sim1', 'sim2'], tvt_dict={'train': 0.8, 'val': 0.1, 'test': 0.1}, zindices=[0, 17, 35, 52, 70, 88, 105, 123, 140, 158, 176, 193, 211, 229, 246, 264, 281, 299, 317, 334, 352, 370, 387, 405, 422, 440, 458, 475, 493, 511], ztransform=['shufflez', 'zoomin']), init_lr=0.001, model_name='model_name', parent_model=None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jsonpickle\n",
    "import numpy as np\n",
    "\n",
    "class DataHyperparameters():\n",
    "    def __init__(self, /, **kwargs):\n",
    "        #Defaults\n",
    "        self.tvt_dict = {\"train\":0.8, \"val\":0.10, \"test\":0.10}\n",
    "        self.lenlimit = -1\n",
    "        \n",
    "        #kwargs\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        #Other attributes for convenience\n",
    "        self.n_datasets = len(kwargs.get(\"data_paths\", []))\n",
    "        self.n_channels = len(kwargs.get(\"zindices\", []))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        keys = sorted(self.__dict__)\n",
    "        items = (\"{}={!r}\".format(k, self.__dict__[k]) for k in keys)\n",
    "        return \"{}({})\".format(type(self).__name__, \", \".join(items))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.__dict__ == other.__dict__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ModelHyperparameters():\n",
    "    def __init__(self, /, **kwargs):\n",
    "        #kwargs\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        keys = sorted(self.__dict__)\n",
    "        items = (\"{}={!r}\".format(k, self.__dict__[k]) for k in keys)\n",
    "        return \"{}({})\".format(type(self).__name__, \", \".join(items))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.__dict__ == other.__dict__\n",
    "\n",
    "\n",
    "\n",
    "hp_train_data = DataHyperparameters(\n",
    "    sims=[\"sim1\", \"sim2\"],\n",
    "    data_paths=[\"path1\", \"path2\"],\n",
    "    zindices=np.linspace(0, 511, 30, dtype=int).tolist(),\n",
    "    batchsize=64,\n",
    "    boxlength=256,\n",
    "    param_index=1,\n",
    "    ztransform=[\"shufflez\",\"zoomin\"],\n",
    "    lenlimit=200,\n",
    ")\n",
    "\n",
    "hp_model = ModelHyperparameters(\n",
    "    model_name=\"model_name\", \n",
    "    hp_data=hp_train_data, \n",
    "    epochs=2000, \n",
    "    init_lr=0.001,\n",
    "    parent_model=None,\n",
    ")\n",
    "\n",
    "\n",
    "def save_hyperparameters(hp):\n",
    "    with open(f\"test_hyperparameters.json\", 'w') as f:\n",
    "        pickle = jsonpickle.encode(hp, indent=4)\n",
    "        f.write(pickle)\n",
    "\n",
    "def load_hyperparameters(path):\n",
    "    with open(path, 'r') as f:\n",
    "        jsonstr = f.read()\n",
    "    return jsonpickle.decode(jsonstr)\n",
    "\n",
    "save_hyperparameters(hp_model)\n",
    "\n",
    "x = load_hyperparameters(f\"test_hyperparameters.json\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d36686-c002-4772-a331-dcbca50e1416",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f496ea91-e90d-40bc-a85e-89bfad649320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([60, 3])\n",
      "tensor([[8., 2., 8.],\n",
      "        [8., 2., 8.],\n",
      "        [8., 2., 8.],\n",
      "        [8., 2., 8.],\n",
      "        [8., 2., 8.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.Tensor([[8,2,8],[9,1.5,9.5]])\n",
    "\n",
    "print(a.shape)\n",
    "b = torch.repeat_interleave(a, 30, dim=0)\n",
    "print(b.shape)\n",
    "print(b[:5])\n",
    "\n",
    "torch.mean(a, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "036e57c8-5ebb-44a5-825a-896d62777d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n",
      "\n",
      "MSE:\n",
      "508.662\n",
      "0.166\n",
      "\n",
      "BCE:\n",
      "3068.094\n",
      "0.999\n",
      "\n",
      "CC:\n",
      "192.242\n",
      "1.001\n",
      "\n",
      "Summed BCE / Summed CC:\n",
      "15.960\n",
      "\n",
      "Summed MSE / Summed CC:\n",
      "2.646\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def corrcoef_loss(input, target, reduction='mean'):    \n",
    "    # Covariance\n",
    "    X = torch.cat((input, target), dim=-2)\n",
    "    X -= torch.mean(X, -1, keepdim=True)\n",
    "    X_T = torch.transpose(X, -2, -1)\n",
    "    c = torch.matmul(X, X_T) / (X.shape[-1] - 1)\n",
    "\n",
    "    # Correlation Coefficient\n",
    "    d = torch.diagonal(c, dim1=-1, dim2=-2)\n",
    "    dd = torch.where(d == 0, 1, d)\n",
    "\n",
    "    stddev = torch.sqrt(dd)\n",
    "    c /= stddev[:,:,:,None]\n",
    "    c /= stddev[:,:,None,:]\n",
    "\n",
    "    #1 - Cross-Correlation\n",
    "    ccd = 1-torch.diagonal(c, offset=c.shape[-1]//2, dim1=-1, dim2=-2)\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        return ccd.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return ccd.sum()\n",
    "    return ccd\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "channels = 3\n",
    "imsize = 16\n",
    "shape = (batch_size, channels, imsize, imsize)\n",
    "params = batch_size*channels*imsize**2\n",
    "print(params)\n",
    "\n",
    "a = torch.rand(shape)\n",
    "#a = torch.arange(params).reshape(shape) / params\n",
    "b = torch.rand(shape)\n",
    "#b = torch.where(a <0.8, 0.0, 1.0)\n",
    "a.requires_grad = True\n",
    "b.requires_grad = True\n",
    "\n",
    "\n",
    "u = nn.functional.mse_loss(a, b, reduction='sum')\n",
    "v = nn.functional.mse_loss(a, b, reduction='mean')\n",
    "\n",
    "w = nn.functional.binary_cross_entropy(a, b, reduction='sum')\n",
    "x = nn.functional.binary_cross_entropy(a, b, reduction='mean')\n",
    "\n",
    "y = corrcoef_loss(a, b, reduction='sum')\n",
    "z = corrcoef_loss(a, b, reduction='mean')\n",
    "\n",
    "print(\"\\nMSE:\")\n",
    "print(f\"{u.item():.3f}\")\n",
    "print(f\"{v.item():.3f}\")\n",
    "\n",
    "print(\"\\nBCE:\")\n",
    "print(f\"{w.item():.3f}\")\n",
    "print(f\"{x.item():.3f}\")\n",
    "\n",
    "print(\"\\nCC:\")\n",
    "print(f\"{y.item():.3f}\")\n",
    "print(f\"{z.item():.3f}\")\n",
    "\n",
    "print(\"\\nSummed BCE / Summed CC:\")\n",
    "print(f\"{(w / y).item():.3f}\")\n",
    "\n",
    "print(\"\\nSummed MSE / Summed CC:\")\n",
    "print(f\"{(u / y).item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ab4ae10-a27e-4d3b-98dc-f486c054d663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE:\n",
      "1.297\n",
      "0.000\n",
      "\n",
      "BCE:\n",
      "1499.751\n",
      "0.488\n",
      "\n",
      "CC:\n",
      "0.235\n",
      "0.001\n",
      "\n",
      "Summed BCE / Summed CC:\n",
      "6388.668\n",
      "\n",
      "Summed MSE / Summed CC:\n",
      "5.525\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(shape)\n",
    "#a = torch.arange(params).reshape(shape) / params\n",
    "b = torch.where(a < 0.5, a*0.9, a)\n",
    "a.requires_grad = True\n",
    "b.requires_grad = True\n",
    "\n",
    "\n",
    "u = nn.functional.mse_loss(a, b, reduction='sum')\n",
    "v = nn.functional.mse_loss(a, b, reduction='mean')\n",
    "\n",
    "w = nn.functional.binary_cross_entropy(a, b, reduction='sum')\n",
    "x = nn.functional.binary_cross_entropy(a, b, reduction='mean')\n",
    "\n",
    "y = corrcoef_loss(a, b, reduction='sum')\n",
    "z = corrcoef_loss(a, b, reduction='mean')\n",
    "\n",
    "print(\"\\nMSE:\")\n",
    "print(f\"{u.item():.3f}\")\n",
    "print(f\"{v.item():.3f}\")\n",
    "\n",
    "print(\"\\nBCE:\")\n",
    "print(f\"{w.item():.3f}\")\n",
    "print(f\"{x.item():.3f}\")\n",
    "\n",
    "print(\"\\nCC:\")\n",
    "print(f\"{y.item():.3f}\")\n",
    "print(f\"{z.item():.3f}\")\n",
    "\n",
    "print(\"\\nSummed BCE / Summed CC:\")\n",
    "print(f\"{(w / y).item():.3f}\")\n",
    "\n",
    "print(\"\\nSummed MSE / Summed CC:\")\n",
    "print(f\"{(u / y).item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30821a2-d76c-4da3-b63d-85423bc76eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n",
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def func(*args):\n",
    "    print(args)\n",
    "    print(*args)\n",
    "\n",
    "func(1, 2, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09f9df6-5ab0-42e5-be88-b03716b4da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import corrcoef"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
